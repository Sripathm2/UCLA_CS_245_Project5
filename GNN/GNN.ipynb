{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZPc4X6x6xdA"
      },
      "source": [
        "!pip install spektral\n",
        "import spektral\n",
        "import numpy as np\n",
        "import scipy.sparse as sp"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZOjcWGAHTAO"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from spektral.data.loaders import SingleLoader\n",
        "from spektral.layers import GCNConv\n",
        "\n",
        "\n",
        "dataset = [spektral.data.Graph(x=np.random.randint(0,1,size=(51,5)), a=sp.csr_matrix((51,51)), e=None)] # Placeholder\n",
        "'''\n",
        "x: np.array, the node features (shape (n_nodes, n_node_features));\n",
        "a: np.array or scipy.sparse matrix, the adjacency matrix (shape (n_nodes, n_nodes));\n",
        "e: np.array, the edge features (shape (n_nodes, n_nodes, n_edge_features) or (n_edges, n_edge_features));\n",
        "'''\n",
        "\n",
        "# Parameters\n",
        "channels = 16          # Number of channels in the first layer\n",
        "dropout = 0.5          # Dropout rate for the features\n",
        "l2_reg = 5e-4 / 2      # L2 regularization rate\n",
        "learning_rate = 1e-2   # Learning rate\n",
        "epochs = 200           # Number of training epochs\n",
        "patience = 10          # Patience for early stopping\n",
        "a_dtype = dataset[0].a.dtype  # Only needed for TF 2.1\n",
        "\n",
        "N = 51          # Number of nodes in the graph\n",
        "F = 5           # Original size of node features\n",
        "y = 5           # Label\n",
        "\n",
        "\n",
        "# Model definition\n",
        "x_in = Input(shape=(F,))\n",
        "a_in = Input((N,), sparse=True, dtype=a_dtype)\n",
        "\n",
        "do_1 = Dropout(dropout)(x_in)\n",
        "gc_1 = GCNConv(channels,\n",
        "               activation='relu',\n",
        "               kernel_regularizer=l2(l2_reg),\n",
        "               use_bias=False)([do_1, a_in])\n",
        "do_2 = Dropout(dropout)(gc_1)\n",
        "gc_2 = GCNConv(y,\n",
        "               activation='softmax',\n",
        "               use_bias=False)([do_2, a_in])\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=[x_in, a_in], outputs=gc_2)\n",
        "optimizer = Adam(lr=learning_rate)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              weighted_metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "# Train model\n",
        "loader = SingleLoader(dataset)\n",
        "model.fit(loader.load(),\n",
        "          steps_per_epoch=loader.steps_per_epoch,\n",
        "          epochs=epochs,\n",
        "          callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}